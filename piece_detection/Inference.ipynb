{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13807,"status":"ok","timestamp":1701834970886,"user":{"displayName":"Tianzheng Gao","userId":"08812738433695606071"},"user_tz":-540},"id":"fef25592","outputId":"3d347c22-62e1-4d7b-851b-a73a73f9a5cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":443,"status":"ok","timestamp":1701834971328,"user":{"displayName":"Tianzheng Gao","userId":"08812738433695606071"},"user_tz":-540},"id":"afsI8HVh7uov","outputId":"db44aa6b-3e0e-4593-f8d5-97f99a45ed26"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/final_proj/task2\n"]}],"source":["cd  \"/content/drive/MyDrive/final_proj/task2\"\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":7206,"status":"ok","timestamp":1701834978531,"user":{"displayName":"Tianzheng Gao","userId":"08812738433695606071"},"user_tz":-540},"id":"29rhCfTqBoZQ"},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms\n","import cv2\n","import numpy as np\n","from PIL import Image\n","import json\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":447,"status":"ok","timestamp":1701834978962,"user":{"displayName":"Tianzheng Gao","userId":"08812738433695606071"},"user_tz":-540},"id":"c2ae4b80"},"outputs":[],"source":["label_map = {'r': 1, 'n': 2, 'b': 3, 'k': 4, 'q': 5, 'p': 6, 'R': 7, 'N': 8, 'B': 9, 'K': 10, 'Q': 11, 'P': 12}\n","reversed_label_map = {v: k for k, v in label_map.items()}\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1701834978963,"user":{"displayName":"Tianzheng Gao","userId":"08812738433695606071"},"user_tz":-540},"id":"516e3327"},"outputs":[],"source":["class ChessDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.image_list = sorted([file for file in os.listdir(os.path.join(root_dir)) if file.endswith('.png')])\n","\n","    def __len__(self):\n","        return len(self.image_list)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        img_name = os.path.join(self.root_dir, self.image_list[idx])\n","        json_name = os.path.splitext(img_name)[0] + \".json\"\n","\n","        image = Image.open(img_name).convert(\"RGB\")\n","        with open(json_name) as f:\n","            annotation = json.load(f)\n","\n","        # extract labels and boxes of chess pieces\n","        pieces_info = annotation['pieces']\n","        labels = [label_map[piece['piece']] for piece in pieces_info]\n","        boxes = [piece['box'] for piece in pieces_info]\n","\n","        # convert box coordinates to (xmin, ymin, xmax, ymax) format\n","        boxes = [[box[0], box[1], box[0] + box[2], box[1] + box[3]] for box in boxes]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        targets = {\n","            'boxes': torch.tensor(boxes, dtype=torch.float32),\n","            'labels': torch.tensor(labels)\n","        }\n","\n","        return image, targets,img_name\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1701834978963,"user":{"displayName":"Tianzheng Gao","userId":"08812738433695606071"},"user_tz":-540},"id":"11495c3e"},"outputs":[],"source":["def collate_fn(batch):\n","    return tuple(zip(*batch))\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1701834978963,"user":{"displayName":"Tianzheng Gao","userId":"08812738433695606071"},"user_tz":-540},"id":"c7672ef3"},"outputs":[],"source":["import torch\n","import torchvision\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection import FasterRCNN\n","from torchvision.models.detection.rpn import AnchorGenerator\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1701834978963,"user":{"displayName":"Tianzheng Gao","userId":"08812738433695606071"},"user_tz":-540},"id":"b3461b21-2d76-44bb-88a4-4eb8ee30b189"},"outputs":[],"source":["def calculate_iou(box1, box2):\n","    # get coordinates of intersection rectangle\n","    x_left = max(box1[0], box2[0])\n","    y_top = max(box1[1], box2[1])\n","    x_right = min(box1[2], box2[2])\n","    y_bottom = min(box1[3], box2[3])\n","\n","    # calculate intersection area\n","    if x_right < x_left or y_bottom < y_top:\n","        return 0.0\n","    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n","\n","    # calculate areas of individual boxes\n","    area_box1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n","    area_box2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n","\n","    # calculate union area\n","    union_area = area_box1 + area_box2 - intersection_area\n","    iou = intersection_area / union_area\n","    return iou\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1701834978963,"user":{"displayName":"Tianzheng Gao","userId":"08812738433695606071"},"user_tz":-540},"id":"8274586e-cb52-4e97-8df9-48ba3d4c7ee3"},"outputs":[],"source":["\n","def find_golden_match(gts, pred, pred_idx, threshold=0.5, ious=None):\n","    golden_match_idx = -1\n","    best_iou = -1\n","\n","    for idx, gt in enumerate(gts):\n","        iou = calculate_iou(gt, pred)\n","\n","        if iou >= threshold and iou > best_iou:\n","            best_iou = iou\n","            golden_match_idx = idx\n","\n","    return golden_match_idx\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1701834978963,"user":{"displayName":"Tianzheng Gao","userId":"08812738433695606071"},"user_tz":-540},"id":"b817362e-186d-4082-903a-9bfe8d8c707d"},"outputs":[],"source":["def calculate_metrics(gts, preds, threshold = 0.5, ious=None) -> float:\n","    n = len(preds)\n","    tp = 0\n","    fp = 0\n","    fns=[1 for i in range(len(gts))]\n","    for pred_idx in range(n):\n","\n","        golden_match_gt_idx = find_golden_match(gts, preds[pred_idx], pred_idx,\n","                                                threshold=threshold, ious=ious)\n","\n","        if golden_match_gt_idx >= 0:\n","            # true positive\n","            tp += 1\n","            # remove matched GT box\n","            fns[golden_match_gt_idx]=0\n","        else:\n","            # false positive, no matching GT box\n","            fp += 1\n","\n","    # false negative, a gt box had no associated predicted box.\n","    fn = sum(fns)\n","    p=tp / (tp + fp + fn)\n","    r=tp / (tp + fn) if (tp + fn) > 0 else 0.0\n","    f1=2*p*r/(p+r) if (p+r)>0 else 0.0\n","    return p,r,f1\n"]},{"cell_type":"markdown","metadata":{"id":"4bd6fa64-714b-43b4-b3f1-690aad97a62a"},"source":["## Predict"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1701834978964,"user":{"displayName":"Tianzheng Gao","userId":"08812738433695606071"},"user_tz":-540},"id":"c2cbed68-714b-4d25-9d24-edcc53d0a55d"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from matplotlib.patches import Rectangle\n"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1701834978964,"user":{"displayName":"Tianzheng Gao","userId":"08812738433695606071"},"user_tz":-540},"id":"315c0711-3cb6-4d57-adfd-6cc2badc4698"},"outputs":[],"source":["def predict(model,test_loader,device):\n","\n","    model.eval()\n","\n","    precisions=[]\n","    recalls=[]\n","    f1s=[]\n","    with torch.no_grad():\n","        for step, (images, targets,image_names) in enumerate(test_loader):\n","            images = list(image.to(device) for image in images)\n","            outputs = model(images)\n","\n","            for i, image in enumerate(images):\n","                detection_threshold = 0.05\n","\n","                sample = image.permute(1,2,0).cpu().numpy()\n","\n","                #image = image.cpu().numpy()\n","                boxes = outputs[i]['boxes'].data.cpu().numpy()\n","                scores = outputs[i]['scores'].data.cpu().numpy()\n","                labels = outputs[i]['labels'].data.cpu().numpy()\n","                valid_indices = scores >= detection_threshold\n","                boxes = boxes[valid_indices].astype(np.int32)\n","                scores = scores[valid_indices]\n","                labels = labels[valid_indices]\n","                gt_boxes = targets[i]['boxes'].cpu().numpy()\n","                preds_sorted_idx = np.argsort(scores)[::-1]\n","                preds_sorted = boxes[preds_sorted_idx]\n","                image_precision,image_recall,image_f1 = calculate_metrics(preds_sorted, gt_boxes)\n","                precisions.append(image_precision)\n","                recalls.append(image_recall)\n","                f1s.append(image_f1)\n","\n","                fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n","\n","                for box, label, score in zip(boxes, labels, scores):\n","                    box_coords = (box[0], box[1]), box[2] - box[0], box[3] - box[1]\n","                    rect = Rectangle(*box_coords, fill=False, edgecolor='red', linewidth=2)\n","                    ax.add_patch(rect)\n","                    label=reversed_label_map[label]\n","                    label_text = f\"{label}:{score:.2f}\"\n","                    ax.text(box[0], box[1], label_text, bbox=dict(facecolor='white', alpha=0.5))\n","\n","                ax.set_axis_off()\n","                ax.imshow(sample)\n","                plt.tight_layout(pad=0)\n","                plt.savefig('results/' + image_names[i][5:])\n","                print(image_names[i][5:] + ' saved')\n","                with open('results/'+image_names[i][5:][:-4]+'.json', 'w') as json_file:\n","                    json.dump({\"boxes\":boxes.tolist(),\"labels\":labels.tolist(),\"scores\":scores.tolist()}, json_file)\n","                print(image_names[i][5:][:-4]+'.json' + ' saved')\n","    test_prec = np.mean(precisions)\n","    test_recall = np.mean(recalls)\n","    test_f1=np.mean(f1s)\n","    return test_prec,test_recall,test_f1\n"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1701834978964,"user":{"displayName":"Tianzheng Gao","userId":"08812738433695606071"},"user_tz":-540},"id":"e9aeef5b-0f8a-4fd3-862a-f9e97f551aeb"},"outputs":[],"source":["batch_size=18\n","transform = transforms.Compose([transforms.ToTensor()])\n","test_directory=\"test/\"\n","test_dataset = ChessDataset(test_directory, transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9805,"status":"ok","timestamp":1701834988758,"user":{"displayName":"Tianzheng Gao","userId":"08812738433695606071"},"user_tz":-540},"id":"4b6c917f-978f-4e02-817b-0a9819c0c7dd","outputId":"8c8056c4-d157-4e22-e581-121c35db8c54"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n","100%|██████████| 160M/160M [00:01<00:00, 128MB/s]\n"]},{"data":{"text/plain":["FasterRCNN(\n","  (transform): GeneralizedRCNNTransform(\n","      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n","  )\n","  (backbone): BackboneWithFPN(\n","    (body): IntermediateLayerGetter(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): FrozenBatchNorm2d(256, eps=0.0)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(512, eps=0.0)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(1024, eps=0.0)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (4): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (5): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(2048, eps=0.0)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","    (fpn): FeaturePyramidNetwork(\n","      (inner_blocks): ModuleList(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (2): Conv2dNormActivation(\n","          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","      )\n","      (layer_blocks): ModuleList(\n","        (0-3): 4 x Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","      )\n","      (extra_blocks): LastLevelMaxPool()\n","    )\n","  )\n","  (rpn): RegionProposalNetwork(\n","    (anchor_generator): AnchorGenerator()\n","    (head): RPNHead(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (1): ReLU(inplace=True)\n","        )\n","      )\n","      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (roi_heads): RoIHeads(\n","    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n","    (box_head): TwoMLPHead(\n","      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n","    )\n","    (box_predictor): FastRCNNPredictor(\n","      (cls_score): Linear(in_features=1024, out_features=13, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=52, bias=True)\n","    )\n","  )\n",")"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","num_classes = 13 # 12 class + background\n","\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","params = [p for p in model.parameters() if p.requires_grad]\n","\n","\n","\n","model.load_state_dict(torch.load(\"models/best_model_ep5_s100_f11.0.pth\"))\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","output_embedded_package_id":"1bnaXkIJPefvy3kZr_JbqBLFk92mSfDY5"},"id":"dc499bf1-bd03-4e67-9e97-90254e95ed21","outputId":"eb851fe5-c9ba-4610-a3b2-3df3d8d60a36"},"outputs":[],"source":["test_prec,test_recall,test_f1=predict(model,test_loader,device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"24b369fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test results: preicison 0.9536442835138548 recall 0.9539949483806488 f1 0.9538158512966417\n"]}],"source":["print(\"Test results: precison \" + str(test_prec) + \" recall \" + str(test_recall) + \" f1 \"+str(test_f1))\n"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"kernelspec":{"display_name":"cp","language":"python","name":"cp"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":5}
